{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAME: P NIKHIL KRISHNA<a href=\"#NAME:-P-NIKHIL-KRISHNA\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "# ROLL NO: HU21CSEN0300328<a href=\"#ROLL-NO:-HU21CSEN0300328\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "# USECASE - 2<a href=\"#USECASE---2\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "# Directory<a href=\"#Directory\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "    import os\n",
    "    os.getcwd()\n",
    "\n",
    "Out\\[2\\]:\n",
    "\n",
    "    'C:\\\\Users\\\\mpaga\\\\Desktop\\\\DL USECASE-2'\n",
    "\n",
    "# Importing Libraries<a href=\"#Importing-Libraries\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    !pip install keras-preprocessing\n",
    "    import keras\n",
    "    from keras_preprocessing.sequence import pad_sequences\n",
    "    from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    from keras.models import Sequential\n",
    "    import keras.utils as ku \n",
    "\n",
    "    Defaulting to user installation because normal site-packages is not writeable\n",
    "    Requirement already satisfied: keras-preprocessing in c:\\users\\mpaga\\appdata\\roaming\\python\\python310\\site-packages (1.1.2)\n",
    "    Requirement already satisfied: numpy>=1.9.1 in c:\\users\\mpaga\\appdata\\roaming\\python\\python310\\site-packages (from keras-preprocessing) (1.24.3)\n",
    "    Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-preprocessing) (1.16.0)\n",
    "    WARNING:tensorflow:From C:\\Users\\mpaga\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(1) \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import string, os \n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Loading the Dataset<a href=\"#Loading-the-Dataset\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    data= pd.read_csv('USECASE2.csv')\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    data.head(20)\n",
    "\n",
    "Out\\[7\\]:\n",
    "\n",
    "|     | Name      | Description                                       |\n",
    "|-----|-----------|---------------------------------------------------|\n",
    "| 0   | Nikhil    | Nikhil is a movie buff with a particular fondn... |\n",
    "| 1   | Manusree  | Manusree is a fashion designer who creates ele... |\n",
    "| 2   | Sreya     | Sreya runs a successful bakery chain in Hydera... |\n",
    "| 3   | Vamsi     | Vamsi loves watching movie.His excitement peak... |\n",
    "| 4   | Arjun     | Arjun has recently started his startup company... |\n",
    "| 5   | Toretto   | Toretto is a kind-hearted person who cares abo... |\n",
    "| 6   | Letty     | Letty combines her unparalleled driving skill...  |\n",
    "| 7   | Preeti    | Preeti's cousin is a travel blogger who share...  |\n",
    "| 8   | Chanakya  | Chanakya's digital marketing strategies are li... |\n",
    "| 9   | Nisha     | Nisha's confidence made our project a success     |\n",
    "| 10  | Anika     | Anika secured a First Rank in her school when ... |\n",
    "| 11  | Sahiti    | Sahithi mesmerizes audiences with her captivat... |\n",
    "| 12  | Aryan     | Arya pioneers in the gaming industry, leading ... |\n",
    "| 13  | Manohar   | Manohar is a big fan of James Bond Flims 007      |\n",
    "| 14  | Isha      | Isha is known for her creativity and talent.      |\n",
    "| 15  | Lekhya    | Lekhya and Isha are inseparable and always tog... |\n",
    "| 16  | Nainika   | Nanikia is an amazing dancer who lights up the... |\n",
    "| 17  | Nisman    | Nisman's reels are like snippets from our own ... |\n",
    "| 18  | Rashmitha | Rashmitha always shows full dedication to her ... |\n",
    "| 19  | Ritika    | Ritika, a self-proclaimed gym freak, has an in... |\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    text=pd.DataFrame()\n",
    "    text['Description']=data.Description\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    text.shape\n",
    "\n",
    "Out\\[9\\]:\n",
    "\n",
    "    (50, 1)\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    text.head(5)\n",
    "\n",
    "Out\\[10\\]:\n",
    "\n",
    "|     | Description                                       |\n",
    "|-----|---------------------------------------------------|\n",
    "| 0   | Nikhil is a movie buff with a particular fondn... |\n",
    "| 1   | Manusree is a fashion designer who creates ele... |\n",
    "| 2   | Sreya runs a successful bakery chain in Hydera... |\n",
    "| 3   | Vamsi loves watching movie.His excitement peak... |\n",
    "| 4   | Arjun has recently started his startup company... |\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    text.describe()\n",
    "\n",
    "Out\\[12\\]:\n",
    "\n",
    "|        | Description                                       |\n",
    "|--------|---------------------------------------------------|\n",
    "| count  | 50                                                |\n",
    "| unique | 50                                                |\n",
    "| top    | Nikhil is a movie buff with a particular fondn... |\n",
    "| freq   | 1                                                 |\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    all_descriptions = []\n",
    "\n",
    "\n",
    "    all_descriptions= [h for h in text.Description if h != \"Unknown\"]\n",
    "    len(all_descriptions)\n",
    "\n",
    "Out\\[11\\]:\n",
    "\n",
    "    50\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    all_descriptions\n",
    "\n",
    "Out\\[13\\]:\n",
    "\n",
    "    [\"Nikhil is a movie buff with a particular fondness for Fast and Furious, alongside his love for cinema. When he's not enjoying high-octane action on screen, he's likely honing his badminton skills.\",\n",
    "     \"Manusree is a fashion designer who creates elegant Indian ethnic wear. She's inspired by traditional craftsmanship and loves incorporating vibrant colors into her designs\",\n",
    "     'Sreya runs a successful bakery chain in Hyderabad with over 10 outlets. Her dedication and passion for baking have made her a household name in the city',\n",
    "     'Vamsi loves watching movie.His excitement peaks when he secures tickets for first-day-first-show screenings, eager to be among the first to witness the magic unfold.\\n\\n\\n\\n',\n",
    "     \"Arjun has recently started his startup company. He's known for his innovative ideas and strategic business acumen.\",\n",
    "     'Toretto is a kind-hearted person who cares about his family',\n",
    "     'Letty  combines her unparalleled driving skills with a resilient spirit, making her a force to be reckoned with on and off the streets.',\n",
    "     \"Preeti's cousin  is a travel blogger who shares her experiences exploring different parts of India and the world. Her blog inspires others to travel and experience new cultures.\",\n",
    "     \"Chanakya's digital marketing strategies are like a symphony of success, orchestrating brand visibility and business growth with precision\",\n",
    "     \"Nisha's confidence made our project a success\",\n",
    "     'Anika secured a First Rank in her school when she was in 9th class',\n",
    "     'Sahithi mesmerizes audiences with her captivating content and InstaReels.',\n",
    "     'Arya pioneers in the gaming industry, leading players on epic adventures through virtual realms where imagination knows no bounds.',\n",
    "     'Manohar is a big fan of James Bond Flims 007',\n",
    "     'Isha is known for her creativity and talent.',\n",
    "     \"Lekhya and Isha are inseparable and always together. They share everything, from secrets to snacks, and they're always there for each other no matter what\",\n",
    "     \"Nanikia is an amazing dancer who lights up the stage with her moves. She's so good that she even participated in DHEE!\",\n",
    "     \"Nisman's reels are like snippets from our own life, capturing moments that feel so relatable\",\n",
    "     'Rashmitha always shows full dedication to her studies .Her determination and resilience have made her a role model among her peers.',\n",
    "     'Ritika, a self-proclaimed gym freak, has an insatiable passion for fitness that sets her apart from the crowd.She is known for her cool and jovial personality',\n",
    "     \"Bharawaj is known for his cool and composed nature, a person who doesn't let small things ruffle his feelings\",\n",
    "     'Vijay always dream to become a successful superstar',\n",
    "     \"Vishnu always gets roasted by his friends. He feels sad but doesn't express it \",\n",
    "     'Venu is a helpful friend who always lends a hand when you need it',\n",
    "     'Gopal has to work on his anger issues',\n",
    "     'Tejaswini is a smart student who loves learning new things',\n",
    "     'Sreeleela dances with grace and joy, spreading happiness with every step',\n",
    "     'Kanupriya and her best friend always explores new places.',\n",
    "     'Rohit shapes cultural narratives in entertainment, captivating audiences with his compelling storytelling and visionary filmmaking',\n",
    "     'Samantha shines on stage or screen, bringing characters to life with her love for acting',\n",
    "     'Revanth has a beautiful voice and loves to sing',\n",
    "     'Kriti Sanon is known for her dedication and commitment to every event she undertakes',\n",
    "     'Jason loves watching  action movies. He always observes different type of actions ',\n",
    "     'Yashna loves her parents very much. She is gonna surprise them next week ',\n",
    "     'Divya is a teacher who teaches Hindi at a primary school. She is passionate about her language and culture',\n",
    "     'Vennela is a student who is studying medicine at a top university',\n",
    "     \"Bhoomi's art designs are captivatingly intriguing, drawing viewers into a world of creativity and imagination\",\n",
    "     'Meenakshi',\n",
    "     'Chaitanya is a hard worker who always gives his best effort',\n",
    "     'Vishwa is a good friend who always been supportive',\n",
    "     'Manognaa is learning to play badminton',\n",
    "     'Karthikey showcasts his creativity and skill in transforming raw footage into captivating content',\n",
    "     'Rudhvik enjoys spending time with his close friends from 10th grade',\n",
    "     'Vishwa is an introverted individual who values his solitude and prefers quiet contemplation over social gatherings',\n",
    "     'Sravya is a diligent student who devotes a significant amount of time to studying',\n",
    "     'Rishit always completes a new game in 2 days',\n",
    "     'Yashawi loves to travel, eagerly  wants to explore new destinations',\n",
    "     'Rohan always sleeps during classes',\n",
    "     'Sandeep once caught his friend hiding his pen in his bag',\n",
    "     'Akshay, once a dull student, now owns many buildings']\n",
    "\n",
    "# DATASET PREPARTION<a href=\"#DATASET-PREPARTION\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "# Dataset Cleaning<a href=\"#Dataset-Cleaning\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    def clean_text(txt):\n",
    "        txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "        txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "        return txt \n",
    "\n",
    "    corpus = [clean_text(x) for x in all_descriptions]\n",
    "    corpus[:10]\n",
    "\n",
    "Out\\[14\\]:\n",
    "\n",
    "    ['nikhil is a movie buff with a particular fondness for fast and furious alongside his love for cinema when hes not enjoying highoctane action on screen hes likely honing his badminton skills',\n",
    "     'manusree is a fashion designer who creates elegant indian ethnic wear shes inspired by traditional craftsmanship and loves incorporating vibrant colors into her designs',\n",
    "     'sreya runs a successful bakery chain in hyderabad with over 10 outlets her dedication and passion for baking have made her a household name in the city',\n",
    "     'vamsi loves watching moviehis excitement peaks when he secures tickets for firstdayfirstshow screenings eager to be among the first to witness the magic unfold\\n\\n\\n\\n',\n",
    "     'arjun has recently started his startup company hes known for his innovative ideas and strategic business acumen',\n",
    "     'toretto is a kindhearted person who cares about his family',\n",
    "     'letty  combines her unparalleled driving skills with a resilient spirit making her a force to be reckoned with on and off the streets',\n",
    "     'preetis cousin  is a travel blogger who shares her experiences exploring different parts of india and the world her blog inspires others to travel and experience new cultures',\n",
    "     'chanakyas digital marketing strategies are like a symphony of success orchestrating brand visibility and business growth with precision',\n",
    "     'nishas confidence made our project a success']\n",
    "\n",
    "# Generating Sequence of N-gram Tokens<a href=\"#Generating-Sequence-of-N-gram-Tokens\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "    all_descriptions[0]\n",
    "\n",
    "Out\\[15\\]:\n",
    "\n",
    "    \"Nikhil is a movie buff with a particular fondness for Fast and Furious, alongside his love for cinema. When he's not enjoying high-octane action on screen, he's likely honing his badminton skills.\"\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    def get_sequence_of_tokens(corpus):\n",
    "        ## tokenization\n",
    "        tokenizer.fit_on_texts(corpus)\n",
    "        total_words = len(tokenizer.word_index) + 1\n",
    "        \n",
    "        ## convert data to sequence of tokens \n",
    "        input_sequences = []\n",
    "        for line in corpus:\n",
    "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "            for i in range(1, len(token_list)):\n",
    "                n_gram_sequence = token_list[:i+1]\n",
    "                input_sequences.append(n_gram_sequence)\n",
    "        return input_sequences, total_words\n",
    "\n",
    "    inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "    inp_sequences[:10]\n",
    "\n",
    "Out\\[16\\]:\n",
    "\n",
    "    [[82, 3],\n",
    "     [82, 3, 1],\n",
    "     [82, 3, 1, 83],\n",
    "     [82, 3, 1, 83, 84],\n",
    "     [82, 3, 1, 83, 84, 8],\n",
    "     [82, 3, 1, 83, 84, 8, 1],\n",
    "     [82, 3, 1, 83, 84, 8, 1, 85],\n",
    "     [82, 3, 1, 83, 84, 8, 1, 85, 86],\n",
    "     [82, 3, 1, 83, 84, 8, 1, 85, 86, 9],\n",
    "     [82, 3, 1, 83, 84, 8, 1, 85, 86, 9, 87]]\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    text1 = tokenizer.sequences_to_texts([[82, 3]])\n",
    "    text2=  tokenizer.sequences_to_texts([[82, 3,1]])\n",
    "    text3=  tokenizer.sequences_to_texts([[82, 3,1,83]])\n",
    "    print(text1,text2,text3)\n",
    "\n",
    "    ['nikhil is'] ['nikhil is a'] ['nikhil is a movie']\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    def generate_padded_sequences(input_sequences):\n",
    "        max_sequence_len = max([len(x) for x in input_sequences])\n",
    "        input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "        \n",
    "        predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "        label = ku.to_categorical(label, num_classes=total_words)\n",
    "        return predictors, label, max_sequence_len\n",
    "\n",
    "    predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    print(predictors, label)\n",
    "\n",
    "    [[  0   0   0 ...   0   0  82]\n",
    "     [  0   0   0 ...   0  82   3]\n",
    "     [  0   0   0 ...  82   3   1]\n",
    "     ...\n",
    "     [  0   0   0 ... 417  24 418]\n",
    "     [  0   0   0 ...  24 418 419]\n",
    "     [  0   0   0 ... 418 419 420]] [[0. 0. 0. ... 0. 0. 0.]\n",
    "     [0. 1. 0. ... 0. 0. 0.]\n",
    "     [0. 0. 0. ... 0. 0. 0.]\n",
    "     ...\n",
    "     [0. 0. 0. ... 1. 0. 0.]\n",
    "     [0. 0. 0. ... 0. 1. 0.]\n",
    "     [0. 0. 0. ... 0. 0. 1.]]\n",
    "\n",
    "# Buliding LSTM MODEL<a href=\"#Buliding-LSTM-MODEL\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    def LSTM_model(max_sequence_len, total_words):\n",
    "        input_len = max_sequence_len - 1\n",
    "        model = Sequential()\n",
    "\n",
    "        \n",
    "        model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "\n",
    "        \n",
    "        model.add(LSTM(100))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        \n",
    "        model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "    LSTMmodel = LSTM_model(max_sequence_len, total_words)\n",
    "    LSTMmodel.summary()\n",
    "\n",
    "    Model: \"sequential_2\"\n",
    "    _________________________________________________________________\n",
    "     Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "     embedding_2 (Embedding)     (None, 31, 10)            4220      \n",
    "                                                                     \n",
    "     lstm_2 (LSTM)               (None, 100)               44400     \n",
    "                                                                     \n",
    "     dropout_2 (Dropout)         (None, 100)               0         \n",
    "                                                                     \n",
    "     dense_2 (Dense)             (None, 422)               42622     \n",
    "                                                                     \n",
    "    =================================================================\n",
    "    Total params: 91242 (356.41 KB)\n",
    "    Trainable params: 91242 (356.41 KB)\n",
    "    Non-trainable params: 0 (0.00 Byte)\n",
    "    _________________________________________________________________\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    LSTMmodel.fit(predictors, label, epochs=100, verbose=5)\n",
    "\n",
    "    Epoch 1/100\n",
    "    WARNING:tensorflow:From C:\\Users\\mpaga\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
    "\n",
    "    WARNING:tensorflow:From C:\\Users\\mpaga\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
    "\n",
    "    Epoch 2/100\n",
    "    Epoch 3/100\n",
    "    Epoch 4/100\n",
    "    Epoch 5/100\n",
    "    Epoch 6/100\n",
    "    Epoch 7/100\n",
    "    Epoch 8/100\n",
    "    Epoch 9/100\n",
    "    Epoch 10/100\n",
    "    Epoch 11/100\n",
    "    Epoch 12/100\n",
    "    Epoch 13/100\n",
    "    Epoch 14/100\n",
    "    Epoch 15/100\n",
    "    Epoch 16/100\n",
    "    Epoch 17/100\n",
    "    Epoch 18/100\n",
    "    Epoch 19/100\n",
    "    Epoch 20/100\n",
    "    Epoch 21/100\n",
    "    Epoch 22/100\n",
    "    Epoch 23/100\n",
    "    Epoch 24/100\n",
    "    Epoch 25/100\n",
    "    Epoch 26/100\n",
    "    Epoch 27/100\n",
    "    Epoch 28/100\n",
    "    Epoch 29/100\n",
    "    Epoch 30/100\n",
    "    Epoch 31/100\n",
    "    Epoch 32/100\n",
    "    Epoch 33/100\n",
    "    Epoch 34/100\n",
    "    Epoch 35/100\n",
    "    Epoch 36/100\n",
    "    Epoch 37/100\n",
    "    Epoch 38/100\n",
    "    Epoch 39/100\n",
    "    Epoch 40/100\n",
    "    Epoch 41/100\n",
    "    Epoch 42/100\n",
    "    Epoch 43/100\n",
    "    Epoch 44/100\n",
    "    Epoch 45/100\n",
    "    Epoch 46/100\n",
    "    Epoch 47/100\n",
    "    Epoch 48/100\n",
    "    Epoch 49/100\n",
    "    Epoch 50/100\n",
    "    Epoch 51/100\n",
    "    Epoch 52/100\n",
    "    Epoch 53/100\n",
    "    Epoch 54/100\n",
    "    Epoch 55/100\n",
    "    Epoch 56/100\n",
    "    Epoch 57/100\n",
    "    Epoch 58/100\n",
    "    Epoch 59/100\n",
    "    Epoch 60/100\n",
    "    Epoch 61/100\n",
    "    Epoch 62/100\n",
    "    Epoch 63/100\n",
    "    Epoch 64/100\n",
    "    Epoch 65/100\n",
    "    Epoch 66/100\n",
    "    Epoch 67/100\n",
    "    Epoch 68/100\n",
    "    Epoch 69/100\n",
    "    Epoch 70/100\n",
    "    Epoch 71/100\n",
    "    Epoch 72/100\n",
    "    Epoch 73/100\n",
    "    Epoch 74/100\n",
    "    Epoch 75/100\n",
    "    Epoch 76/100\n",
    "    Epoch 77/100\n",
    "    Epoch 78/100\n",
    "    Epoch 79/100\n",
    "    Epoch 80/100\n",
    "    Epoch 81/100\n",
    "    Epoch 82/100\n",
    "    Epoch 83/100\n",
    "    Epoch 84/100\n",
    "    Epoch 85/100\n",
    "    Epoch 86/100\n",
    "    Epoch 87/100\n",
    "    Epoch 88/100\n",
    "    Epoch 89/100\n",
    "    Epoch 90/100\n",
    "    Epoch 91/100\n",
    "    Epoch 92/100\n",
    "    Epoch 93/100\n",
    "    Epoch 94/100\n",
    "    Epoch 95/100\n",
    "    Epoch 96/100\n",
    "    Epoch 97/100\n",
    "    Epoch 98/100\n",
    "    Epoch 99/100\n",
    "    Epoch 100/100\n",
    "\n",
    "Out\\[23\\]:\n",
    "\n",
    "    <keras.src.callbacks.History at 0x2491dc3d630>\n",
    "\n",
    "# Performance of LSTM MODEL<a href=\"#Performance-of-LSTM-MODEL\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[24\\]:\n",
    "\n",
    "    loss, accuracy = LSTMmodel.evaluate(predictors, label)\n",
    "    print(\"LSTM Loss:\", loss)\n",
    "    print(\"LSTM Accuracy:\", accuracy)\n",
    "\n",
    "    21/21 [==============================] - 1s 12ms/step - loss: 1.2382 - accuracy: 0.8212\n",
    "    LSTM Loss: 1.238184928894043\n",
    "    LSTM Accuracy: 0.8211624622344971\n",
    "\n",
    "# Generating the text using Trained(LSTM) MODEL<a href=\"#Generating-the-text-using-Trained(LSTM)-MODEL\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[25\\]:\n",
    "\n",
    "    def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "        for _ in range(next_words):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "            predicted = np.argmax(model.predict(token_list,verbose=5), axis=-1)\n",
    "            \n",
    "            output_word = \"\"\n",
    "            for word,index in tokenizer.word_index.items():\n",
    "                if index == predicted:\n",
    "                    output_word = word\n",
    "                    break\n",
    "            seed_text += \" \"+output_word\n",
    "        return seed_text.title()\n",
    "\n",
    "In \\[34\\]:\n",
    "\n",
    "    print(generate_text(\"Ritika\", 5, LSTMmodel, max_sequence_len))\n",
    "    print(generate_text(\"Sreeleela\", 5, LSTMmodel, max_sequence_len))\n",
    "    print(generate_text(\"Isha\", 5, LSTMmodel, max_sequence_len))\n",
    "    print(generate_text(\"Nikhil\", 5, LSTMmodel, max_sequence_len))\n",
    "\n",
    "    Ritika A Selfproclaimed Gym Freak Has\n",
    "    Sreeleela Dances With Grace And Joy\n",
    "    Isha Is Known For Her Creativity\n",
    "    Nikhil Is A Selfproclaimed Gym Freak\n",
    "\n",
    "# BULIDING RNN MODEL<a href=\"#BULIDING-RNN-MODEL\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[35\\]:\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "\n",
    "    def RNN_model(max_sequence_len, total_words):\n",
    "        input_len = max_sequence_len - 1\n",
    "        model = Sequential()\n",
    "\n",
    "        \n",
    "        model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "\n",
    "       \n",
    "        model.add(SimpleRNN(100))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        \n",
    "        model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "In \\[36\\]:\n",
    "\n",
    "    RNNmodel = RNN_model(max_sequence_len, total_words)\n",
    "    RNNmodel.summary()\n",
    "\n",
    "    Model: \"sequential_4\"\n",
    "    _________________________________________________________________\n",
    "     Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "     embedding_4 (Embedding)     (None, 31, 10)            4220      \n",
    "                                                                     \n",
    "     simple_rnn_1 (SimpleRNN)    (None, 100)               11100     \n",
    "                                                                     \n",
    "     dropout_4 (Dropout)         (None, 100)               0         \n",
    "                                                                     \n",
    "     dense_4 (Dense)             (None, 422)               42622     \n",
    "                                                                     \n",
    "    =================================================================\n",
    "    Total params: 57942 (226.34 KB)\n",
    "    Trainable params: 57942 (226.34 KB)\n",
    "    Non-trainable params: 0 (0.00 Byte)\n",
    "    _________________________________________________________________\n",
    "\n",
    "In \\[37\\]:\n",
    "\n",
    "    RNNmodel.fit(predictors, label, epochs=100, verbose=5)\n",
    "\n",
    "    Epoch 1/100\n",
    "    Epoch 2/100\n",
    "    Epoch 3/100\n",
    "    Epoch 4/100\n",
    "    Epoch 5/100\n",
    "    Epoch 6/100\n",
    "    Epoch 7/100\n",
    "    Epoch 8/100\n",
    "    Epoch 9/100\n",
    "    Epoch 10/100\n",
    "    Epoch 11/100\n",
    "    Epoch 12/100\n",
    "    Epoch 13/100\n",
    "    Epoch 14/100\n",
    "    Epoch 15/100\n",
    "    Epoch 16/100\n",
    "    Epoch 17/100\n",
    "    Epoch 18/100\n",
    "    Epoch 19/100\n",
    "    Epoch 20/100\n",
    "    Epoch 21/100\n",
    "    Epoch 22/100\n",
    "    Epoch 23/100\n",
    "    Epoch 24/100\n",
    "    Epoch 25/100\n",
    "    Epoch 26/100\n",
    "    Epoch 27/100\n",
    "    Epoch 28/100\n",
    "    Epoch 29/100\n",
    "    Epoch 30/100\n",
    "    Epoch 31/100\n",
    "    Epoch 32/100\n",
    "    Epoch 33/100\n",
    "    Epoch 34/100\n",
    "    Epoch 35/100\n",
    "    Epoch 36/100\n",
    "    Epoch 37/100\n",
    "    Epoch 38/100\n",
    "    Epoch 39/100\n",
    "    Epoch 40/100\n",
    "    Epoch 41/100\n",
    "    Epoch 42/100\n",
    "    Epoch 43/100\n",
    "    Epoch 44/100\n",
    "    Epoch 45/100\n",
    "    Epoch 46/100\n",
    "    Epoch 47/100\n",
    "    Epoch 48/100\n",
    "    Epoch 49/100\n",
    "    Epoch 50/100\n",
    "    Epoch 51/100\n",
    "    Epoch 52/100\n",
    "    Epoch 53/100\n",
    "    Epoch 54/100\n",
    "    Epoch 55/100\n",
    "    Epoch 56/100\n",
    "    Epoch 57/100\n",
    "    Epoch 58/100\n",
    "    Epoch 59/100\n",
    "    Epoch 60/100\n",
    "    Epoch 61/100\n",
    "    Epoch 62/100\n",
    "    Epoch 63/100\n",
    "    Epoch 64/100\n",
    "    Epoch 65/100\n",
    "    Epoch 66/100\n",
    "    Epoch 67/100\n",
    "    Epoch 68/100\n",
    "    Epoch 69/100\n",
    "    Epoch 70/100\n",
    "    Epoch 71/100\n",
    "    Epoch 72/100\n",
    "    Epoch 73/100\n",
    "    Epoch 74/100\n",
    "    Epoch 75/100\n",
    "    Epoch 76/100\n",
    "    Epoch 77/100\n",
    "    Epoch 78/100\n",
    "    Epoch 79/100\n",
    "    Epoch 80/100\n",
    "    Epoch 81/100\n",
    "    Epoch 82/100\n",
    "    Epoch 83/100\n",
    "    Epoch 84/100\n",
    "    Epoch 85/100\n",
    "    Epoch 86/100\n",
    "    Epoch 87/100\n",
    "    Epoch 88/100\n",
    "    Epoch 89/100\n",
    "    Epoch 90/100\n",
    "    Epoch 91/100\n",
    "    Epoch 92/100\n",
    "    Epoch 93/100\n",
    "    Epoch 94/100\n",
    "    Epoch 95/100\n",
    "    Epoch 96/100\n",
    "    Epoch 97/100\n",
    "    Epoch 98/100\n",
    "    Epoch 99/100\n",
    "    Epoch 100/100\n",
    "\n",
    "Out\\[37\\]:\n",
    "\n",
    "    <keras.src.callbacks.History at 0x2491db67400>\n",
    "\n",
    "# Performance Metrics of RNN Model<a href=\"#Performance-Metrics-of-RNN-Model\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[38\\]:\n",
    "\n",
    "    loss, accuracy = RNNmodel.evaluate(predictors, label)\n",
    "    print(\"RNN Loss:\", loss)\n",
    "    print(\"RNN Accuracy:\", accuracy)\n",
    "\n",
    "    21/21 [==============================] - 1s 6ms/step - loss: 0.1000 - accuracy: 0.9985\n",
    "    RNN Loss: 0.10002611577510834\n",
    "    RNN Accuracy: 0.9985097050666809\n",
    "\n",
    "# Generating Text using Trained(RNN) Model<a href=\"#Generating-Text-using-Trained(RNN)-Model\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[39\\]:\n",
    "\n",
    "    print(generate_text(\"Manohar\", 5, RNNmodel, max_sequence_len))\n",
    "    print(generate_text(\"Ritika\", 5, RNNmodel, max_sequence_len))\n",
    "    print(generate_text(\"Isha\", 5, RNNmodel, max_sequence_len))\n",
    "\n",
    "    Manohar Is A Big Fan Of\n",
    "    Ritika A Selfproclaimed Gym Freak Has\n",
    "    Isha Is Known For Her Creativity\n",
    "\n",
    "# Converting IPYNB to HTML<a href=\"#Converting-IPYNB-to-HTML\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[40\\]:\n",
    "\n",
    "    !jupyter nbconvert --to html \"DL_USECASE2.ipynb\"\n",
    "\n",
    "    [NbConvertApp] Converting notebook DL_USECASE2.ipynb to html\n",
    "    [NbConvertApp] Writing 650083 bytes to DL_USECASE2.html\n",
    "\n",
    "In \\[ \\]:"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
